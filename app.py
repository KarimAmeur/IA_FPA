# PATCH POUR STREAMLIT CLOUD - √Ä placer en tout d√©but de app.py
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    # pysqlite3 n'est pas disponible, continuer avec sqlite3 normal
    pass

import streamlit as st
import os
import zipfile
import shutil
from pathlib import Path
from typing import List

# CORRECTION: Import corrig√© pour Chroma
from langchain_community.vectorstores import Chroma

from langchain_mistralai import ChatMistralAI
from prompting import (
    retrieve_documents,
    generate_context_response,
    generate_example_training_plan,
    generate_pedagogical_engineering_advice,
    reformulate_competencies_apc,
    generate_structured_training_scenario
)

# Import de la page RAG Personnel
from user_rag_page import user_rag_page

# CORRECTION: Import de l'API Mistral pour les embeddings
from mistralai.client import MistralClient

# Configuration des APIs - Utilise les secrets Streamlit
try:
    MISTRAL_API_KEY = st.secrets["MISTRAL_API_KEY"]
    HUGGINGFACE_TOKEN = st.secrets["HUGGINGFACE_TOKEN"]
except:
    MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")
    HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN", "")

# Configurer le token HuggingFace
if HUGGINGFACE_TOKEN:
    os.environ["HUGGINGFACE_HUB_TOKEN"] = HUGGINGFACE_TOKEN

# NOUVELLE CLASSE: Embeddings Mistral compatible avec LangChain
class MistralEmbeddings:
    """
    Wrapper LangChain pour Mistral Embed (1024 dims).
    Compatible avec la base vectorielle cr√©√©e par rag_formation.py
    """
    def __init__(self, api_key: str, model: str = "mistral-embed"):
        self.client = MistralClient(api_key=api_key)
        self.model = model

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        batch_size = 50
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            try:
                resp = self.client.embeddings(model=self.model, input=batch)
                embeddings.extend([d.embedding for d in resp.data])
            except Exception as e:
                st.error(f"Erreur embedding lot {i//batch_size+1}: {e}")
                embeddings.extend([[0.0]*1024 for _ in batch])
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        try:
            resp = self.client.embeddings(model=self.model, input=[text])
            return resp.data[0].embedding
        except Exception as e:
            st.error(f"Erreur embedding requ√™te: {e}")
            return [0.0]*1024

# D√©finition des couleurs
COLORS = {
    "primary": "#1D5B68",
    "secondary": "#E6525E", 
    "light_blue": "#94B7BD",
    "very_light_blue": "#DDE7E9",
    "dark_gray": "#3F3F3F",
    "light_gray": "#F5F5F6",
    "background": "#1A1A1A",
    "text": "#FFFFFF"
}

# Configuration CSS personnalis√©e
def local_css():
    st.markdown(f"""
    <style>
        .stApp {{
            background-color: {COLORS["background"]};
            color: {COLORS["text"]};
        }}
        
        h1, h2, h3 {{
            color: {COLORS["light_blue"]};
            font-family: 'Helvetica Neue', sans-serif;
        }}
        
        .stTextInput>div>div>input, .stTextArea>div>div>textarea {{
            background-color: {COLORS["dark_gray"]};
            color: {COLORS["text"]};
            border: 1px solid {COLORS["light_blue"]};
        }}
        
        .stSelectbox>div>div>div {{
            background-color: {COLORS["dark_gray"]};
            color: {COLORS["text"]};
            border-radius: 6px;
            border: 1px solid {COLORS["light_blue"]};
        }}
        
        .stButton>button {{
            background-color: {COLORS["primary"]};
            color: {COLORS["text"]};
            border: none;
            border-radius: 6px;
            padding: 8px 16px;
            font-weight: 500;
            transition: all 0.3s;
        }}
        
        .stButton>button:hover {{
            background-color: {COLORS["light_blue"]};
        }}
        
        [data-testid="stSidebar"] {{
            background-color: {COLORS["dark_gray"]};
            color: {COLORS["text"]};
        }}
        
        .scenario-card, .user-message, .assistant-message {{
            background-color: {COLORS["dark_gray"]};
            color: {COLORS["text"]};
            padding: 15px;
            border-radius: 10px;
            border-left: 5px solid {COLORS["secondary"]};
            margin-bottom: 10px;
        }}
        
        .upload-box {{
            background-color: {COLORS["dark_gray"]};
            border: 2px dashed {COLORS["light_blue"]};
            border-radius: 10px;
            padding: 30px;
            text-align: center;
            margin: 20px 0;
        }}
    </style>
    """, unsafe_allow_html=True)

# Configuration de l'application Streamlit
st.set_page_config(
    page_title="Assistant FPA - Ing√©nierie de Formation",
    page_icon="üìò",
    layout="wide",
    initial_sidebar_state="expanded"
)

local_css()

# NOUVELLE FONCTION : Nettoyage automatique ChromaDB
def clean_corrupted_chromadb(db_path):
    """Nettoie automatiquement une base ChromaDB corrompue"""
    try:
        st.warning("üîß D√©tection d'une base ChromaDB incompatible...")
        st.info("üóëÔ∏è Suppression automatique de l'ancienne base...")
        
        # Supprimer le dossier corrompu
        if os.path.exists(db_path):
            shutil.rmtree(db_path)
        
        st.success("‚úÖ Base corrompue supprim√©e avec succ√®s !")
        st.info("üìã Veuillez re-uploader votre fichier chromadb_formation.zip")
        
        return True
    except Exception as e:
        st.error(f"‚ùå Erreur lors du nettoyage: {e}")
        return False

# Fonctions de gestion de la base vectorielle
@st.cache_resource
def extract_database_if_needed():
    """D√©compresse automatiquement la base vectorielle si n√©cessaire"""
    
    db_path = "chromadb_formation"
    zip_path = "chromadb_formation.zip"
    
    # Si le dossier existe d√©j√† et n'est pas vide, pas besoin de d√©compresser
    if os.path.exists(db_path) and os.listdir(db_path):
        st.success("‚úÖ Base vectorielle d√©j√† disponible")
        return True
    
    # Si le zip existe, le d√©compresser
    if os.path.exists(zip_path):
        st.info("üì¶ D√©compression de la base vectorielle...")
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(".")
            
            st.success("‚úÖ Base vectorielle d√©compress√©e avec succ√®s")
            return True
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la d√©compression: {e}")
            return False
    
    return False

def database_upload_interface():
    """Interface d'upload de la base vectorielle"""
    
    st.markdown("""
    <div class="upload-box">
        <h3>üì§ Upload de votre base vectorielle</h3>
        <p>La base vectorielle ChromaDB est n√©cessaire pour le fonctionnement de l'assistant.</p>
    </div>
    """, unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "Choisir le fichier chromadb_formation.zip",
        type="zip",
        help="Uploadez votre base vectorielle compress√©e au format ZIP"
    )
    
    if uploaded_file is not None:
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("üíæ Sauvegarde du fichier...")
            progress_bar.progress(25)
            
            with open("chromadb_formation.zip", "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            status_text.text("üì¶ D√©compression en cours...")
            progress_bar.progress(50)
            
            with zipfile.ZipFile("chromadb_formation.zip", 'r') as zip_ref:
                zip_ref.extractall(".")
            
            progress_bar.progress(100)
            status_text.text("‚úÖ Base vectorielle install√©e avec succ√®s!")
            
            st.success("üéâ Votre base vectorielle a √©t√© install√©e ! L'application va red√©marrer...")
            st.balloons()
            
            import time
            time.sleep(2)
            st.rerun()
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'installation: {e}")
            st.info("üí° Assurez-vous que le fichier ZIP contient bien le dossier 'chromadb_formation'")
    
    return False

# CORRECTION: Fonction de chargement des embeddings Mistral
@st.cache_resource
def load_embedding_model():
    """Charge le mod√®le d'embedding Mistral compatible avec la base vectorielle"""
    try:
        if not MISTRAL_API_KEY:
            st.error("‚ùå Cl√© API Mistral manquante")
            return None
            
        # CORRECTION: Utilisation des embeddings Mistral au lieu de HuggingFace
        return MistralEmbeddings(api_key=MISTRAL_API_KEY, model="mistral-embed")
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du mod√®le d'embedding: {e}")
        return None

@st.cache_resource
def load_vector_store():
    """Charge la base vectorielle avec mise en cache et gestion d'erreurs"""
    try:
        embeddings = load_embedding_model()
        if embeddings is None:
            return None
            
        db_path = "chromadb_formation"
        if not os.path.exists(db_path):
            st.error("‚ùå Base vectorielle 'chromadb_formation' non trouv√©e")
            return None
            
        # CORRECTION: Utilisation du nouveau Chroma avec gestion d'erreur
        try:
            vectorstore = Chroma(
                persist_directory=db_path,
                embedding_function=embeddings
            )
            # Test de fonctionnement
            vectorstore.similarity_search("test", k=1)
            return vectorstore
            
        except Exception as chroma_error:
            error_msg = str(chroma_error).lower()
            
            # D√©tecter l'erreur de colonne manquante
            if "no such column: collections.topic" in error_msg:
                st.error("‚ùå Base ChromaDB incompatible d√©tect√©e")
                
                # Nettoyage automatique
                if clean_corrupted_chromadb(db_path):
                    return "needs_reupload"
                else:
                    return None
                    
            # D√©tecter l'erreur de dimension d'embedding
            elif "embedding dimension" in error_msg and "does not match" in error_msg:
                st.error("‚ùå Incompatibilit√© de dimensions d'embeddings d√©tect√©e")
                st.info("üí° La base vectorielle a √©t√© cr√©√©e avec des embeddings diff√©rents")
                
                # Nettoyage automatique
                if clean_corrupted_chromadb(db_path):
                    return "needs_reupload"
                else:
                    return None
            else:
                # Autre erreur ChromaDB
                st.error(f"‚ùå Erreur ChromaDB: {chroma_error}")
                return None
                
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement de la base vectorielle: {e}")
        return None


@st.cache_resource
def create_mistral_llm():
    """Cr√©e l'instance Mistral avec mise en cache"""
    try:
        if not MISTRAL_API_KEY:
            st.error("‚ùå Cl√© API Mistral manquante")
            return None
            
        return ChatMistralAI(
            mistral_api_key=MISTRAL_API_KEY,
            model="open-mistral-7b",  # ‚Üê MOD√àLE ACCESSIBLE √Ä TOUS LES TIERS
            temperature=0.1,
            max_tokens=4000
        )
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la cr√©ation du mod√®le Mistral: {e}")
        return None

# Initialisation automatique du syst√®me
def initialize_system():
    """Initialise le syst√®me avec gestion automatique de la base et des erreurs"""
    
    # V√©rifier/d√©compresser la base d'abord
    if not extract_database_if_needed():
        return None, None, "database_missing"
    
    with st.spinner("üöÄ Initialisation de l'Assistant FPA..."):
        # Charger la base vectorielle
        vectorstore = load_vector_store()
        
        # V√©rifier si on doit re-uploader
        if vectorstore == "needs_reupload":
            return None, None, "database_missing"
        
        # Charger le mod√®le LLM
        llm = create_mistral_llm()
        
        if vectorstore is None:
            return None, None, "vectorstore_error"
        if llm is None:
            return None, None, "llm_error"
            
        return vectorstore, llm, "success"

# V√©rification et initialisation
if 'initialized' not in st.session_state:
    vectorstore, llm, status = initialize_system()
    st.session_state.vectorstore = vectorstore
    st.session_state.llm = llm
    st.session_state.initialization_status = status
    st.session_state.conversation_history = []
    st.session_state.scenarisation_history = []
    st.session_state.initialized = True

# Gestion des erreurs d'initialisation
if st.session_state.initialization_status == "database_missing":
    st.markdown("""
    <div class="banner">
        <h1>üéì Assistant FPA - Ing√©nierie de Formation</h1>
        <p>Configuration initiale requise</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.warning("‚ö†Ô∏è Base vectorielle non trouv√©e ou incompatible")
    st.info("üìã Veuillez uploader votre base vectorielle pour commencer √† utiliser l'assistant.")
    
    if not database_upload_interface():
        st.stop()

elif st.session_state.initialization_status in ["vectorstore_error", "llm_error"]:
    st.error("‚ùå Erreur lors de l'initialisation du syst√®me")
    
    # Interface de diagnostic
    st.subheader("üîß Diagnostic")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üß™ Tester API Mistral"):
            try:
                from mistralai.client import MistralClient
                client = MistralClient(api_key=MISTRAL_API_KEY)
                models = client.list_models()
                st.success("‚úÖ API Mistral accessible")
            except Exception as e:
                st.error(f"‚ùå Erreur API Mistral: {e}")
    
    with col2:
        if st.button("ü§ó Tester token HuggingFace"):
            try:
                if HUGGINGFACE_TOKEN:
                    from huggingface_hub import whoami
                    info = whoami(token=HUGGINGFACE_TOKEN)
                    st.success(f"‚úÖ Token HF valide: {info['name']}")
                else:
                    st.warning("‚ö†Ô∏è Token HuggingFace non configur√©")
            except Exception as e:
                st.error(f"‚ùå Token HF invalide: {e}")
    
    with col3:
        if st.button("üìÅ V√©rifier base vectorielle"):
            if os.path.exists("chromadb_formation"):
                files = os.listdir("chromadb_formation")
                st.info(f"üìÇ Dossier trouv√© avec {len(files)} fichiers")
            else:
                st.error("‚ùå Dossier 'chromadb_formation' non trouv√©")
    
    if st.button("üîÑ R√©essayer l'initialisation"):
        st.session_state.initialized = False
        st.rerun()
    
    st.stop()

# Page principale de chat
def main_chat_page():
    """Page principale de chat avec l'assistant FPA"""
    
    st.markdown("""
    <div class="banner">
        <h1>üéì Assistant FPA - Ing√©nierie de Formation</h1>
        <p>Votre partenaire intelligent pour la conception et l'am√©lioration de vos formations professionnelles</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Conteneur principal
    chat_container = st.container()
    
    with chat_container:
        # Afficher l'historique de conversation
        for message in st.session_state.conversation_history:
            if message['role'] == 'user':
                st.markdown(f"""
                <div class="user-message">
                    <strong>Vous:</strong><br>
                    {message['content']}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="assistant-message">
                    <strong>Assistant FPA:</strong><br>
                    {message['content']}
                </div>
                """, unsafe_allow_html=True)

        # Input pour le message de l'utilisateur
        if prompt := st.chat_input("Posez votre question sur la formation professionnelle"):
            # Ajouter le message de l'utilisateur √† l'historique
            st.session_state.conversation_history.append({
                'role': 'user', 
                'content': prompt
            })

            # Afficher le message de l'utilisateur
            st.markdown(f"""
            <div class="user-message">
                <strong>Vous:</strong><br>
                {prompt}
            </div>
            """, unsafe_allow_html=True)

            # G√©n√©rer la r√©ponse
            with st.status("üîç Recherche en cours...", expanded=True) as status:
                st.write("üìö Recherche des documents pertinents...")
                retrieved_docs = retrieve_documents(
                    st.session_state.vectorstore, 
                    prompt
                )
                
                st.write("üß† G√©n√©ration de la r√©ponse...")
                response = generate_context_response(
                    st.session_state.llm, 
                    prompt, 
                    retrieved_docs,
                    st.session_state.conversation_history
                )
                
                status.update(label="‚úÖ Recherche termin√©e", state="complete", expanded=False)
                
            # Afficher la r√©ponse
            st.markdown(f"""
            <div class="assistant-message">
                <strong>Assistant FPA:</strong><br>
                {response}
            </div>
            """, unsafe_allow_html=True)

            # Ajouter la r√©ponse √† l'historique
            st.session_state.conversation_history.append({
                'role': 'assistant', 
                'content': response
            })

            # Option d'affichage des documents sources
            with st.expander("üìö Documents sources"):
                for i, doc in enumerate(retrieved_docs, 1):
                    st.markdown(f"""
                    <div class="scenario-card">
                        <h4>Document {i}</h4>
                        <p><span class="badge badge-blue">Score: {doc['score']:.2f}</span></p>
                        <p><strong>Titre:</strong> {doc['title']}</p>
                        <hr>
                        {doc['content']}
                    </div>
                    """, unsafe_allow_html=True)

    # Sidebar avec outils
    st.sidebar.markdown("""
    <div style="text-align: center; margin-bottom: 30px;">
        <div class="logo" style="margin: 0 auto;">FPA</div>
        <h3>Assistant Formation</h3>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.markdown("### üõ†Ô∏è Outils suppl√©mentaires")

    if st.sidebar.button("üìù Exemple de plan de formation"):
        with st.spinner("üìù G√©n√©ration d'un exemple de plan..."):
            exemple_plan = generate_example_training_plan(st.session_state.llm)
            st.markdown(f"""
            <div class="scenario-card">
                <h2>üìù Exemple de Plan de Formation</h2>
                <div class="info-box">
                    Ce plan peut servir de mod√®le pour vos propres formations.
                </div>
                {exemple_plan}
            </div>
            """, unsafe_allow_html=True)

    if st.sidebar.button("üîç Aide √† l'ing√©nierie p√©dagogique"):
        with st.spinner("üîç G√©n√©ration de conseils..."):
            aide_ingenierie = generate_pedagogical_engineering_advice(st.session_state.llm)
            st.markdown(f"""
            <div class="scenario-card">
                <h2>üîç Conseils d'Ing√©nierie P√©dagogique</h2>
                <div class="info-box">
                    Conseils pour am√©liorer vos m√©thodes d'ing√©nierie p√©dagogique.
                </div>
                {aide_ingenierie}
            </div>
            """, unsafe_allow_html=True)

# Page de sc√©narisation (version compl√®te)
def scenarisation_page():
    """Page de sc√©narisation de formation"""
    
    st.markdown("""
    <div class="banner">
        <h1>üéØ Sc√©narisation de Formation</h1>
        <p>Cr√©ez des sc√©narios p√©dagogiques adapt√©s √† vos objectifs</p>
    </div>
    """, unsafe_allow_html=True)
    
    left_col, right_col = st.columns([2, 1])
    
    with left_col:
        st.markdown("""
        <div class="scenario-card">
            <h3>üìã Param√®tres du sc√©nario</h3>
        """, unsafe_allow_html=True)
        
        input_type = st.selectbox(
            "Type d'entr√©e",
            ["Titre", "Programme", "Comp√©tences"]
        )
        
        input_data = st.text_area(f"Contenu de {input_type.lower()}", 
            height=150,
            placeholder=f"Saisissez ici votre {input_type.lower()} de formation..."
        )
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        st.markdown("""
        <div class="scenario-card">
            <h3>‚è±Ô∏è Dur√©e de formation</h3>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            duration_hours = st.number_input("Heures", min_value=0, max_value=40, value=3, step=1)
        with col2:
            duration_minutes = st.number_input("Minutes suppl√©mentaires", min_value=0, max_value=59, value=30, step=5)
        
        total_duration_minutes = (duration_hours * 60) + duration_minutes
        
        st.markdown(f"""
        <div style="margin-top: 10px; margin-bottom: 10px;">
            <span style="background: {COLORS['primary']}; color: white; padding: 5px 10px; border-radius: 5px; font-size: 1rem;">
                ‚è±Ô∏è Dur√©e totale: {duration_hours}h{duration_minutes if duration_minutes > 0 else ''} ({total_duration_minutes} minutes)
            </span>
        </div>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("‚ú® G√©n√©rer le sc√©nario de formation", use_container_width=True):
            if input_data:
                user_content = f"""
                <div>
                    <p><strong>Type d'entr√©e:</strong> {input_type}</p>
                    <p><strong>Contenu:</strong> {input_data}</p>
                    <p><strong>Dur√©e:</strong> {duration_hours}h{duration_minutes if duration_minutes > 0 else ''} ({total_duration_minutes} minutes)</p>
                </div>
                """
                
                st.session_state.scenarisation_history.append({
                    'role': 'user', 
                    'content': user_content
                })
                
                st.markdown(f"""
                <div class="user-message">
                    <strong>Votre demande:</strong><br>
                    {user_content}
                </div>
                """, unsafe_allow_html=True)
                
                with st.status("üéØ Cr√©ation de votre sc√©nario de formation...", expanded=True) as status:
                    input_type_lower = input_type.lower()
                    
                    if input_type_lower == 'competences':
                        st.write("üîÑ Reformulation des comp√©tences selon l'approche par comp√©tences...")
                        reformulated_competencies = reformulate_competencies_apc(
                            st.session_state.llm,
                            st.session_state.vectorstore,
                            input_data
                        )
                        input_data = reformulated_competencies
                    
                    st.write("üìù G√©n√©ration du sc√©nario p√©dagogique...")
                    scenario = generate_structured_training_scenario(
                        st.session_state.llm,
                        st.session_state.vectorstore,
                        input_data,
                        input_type_lower,
                        total_duration_minutes
                    )
                    
                    status.update(label="‚úÖ Sc√©nario termin√©!", state="complete", expanded=False)
                
                st.markdown(f"""
                <div class="assistant-message">
                    <h3>üìã Votre Sc√©nario de Formation</h3>
                    <div class="info-box">
                        Ce sc√©nario a √©t√© g√©n√©r√© en fonction de vos param√®tres.
                    </div>
                    {scenario}
                </div>
                """, unsafe_allow_html=True)
                
                st.session_state.scenarisation_history.append({
                    'role': 'assistant', 
                    'content': scenario
                })
            else:
                st.warning("‚ö†Ô∏è Veuillez saisir un contenu pour g√©n√©rer le sc√©nario.")
                
    with right_col:
        st.markdown("""
        <div class="scenario-card">
            <h3>üí° Guide de sc√©narisation</h3>
            <p>Pour cr√©er un sc√©nario de formation efficace:</p>
            <ol>
                <li><strong>Choisissez un type d'entr√©e</strong></li>
                <li><strong>D√©finissez le contenu</strong> avec d√©tails</li>
                <li><strong>Ajustez la dur√©e</strong> selon vos contraintes</li>
            </ol>
        </div>
        """, unsafe_allow_html=True)

# CORRECTION: Onglets de navigation avec 3 onglets
tab1, tab2, tab3 = st.tabs(["üí¨ Assistant FPA", "üéØ Sc√©narisation", "üìö RAG Personnel"])

with tab1:
    main_chat_page()

with tab2:
    scenarisation_page()

with tab3:
    user_rag_page()  # Appel de la fonction pour afficher la page RAG Personnel